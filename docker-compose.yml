version: '3.3'
services:
  
  # Tyk Gateway
  tyk-gateway:
    image: tykio/tyk-gateway:v5.3.2
    ports:
      - 8080:8080
    networks:
      - tyk
    environment:
        - TYK_GW_OPENTELEMETRY_ENABLED=true
        - TYK_GW_OPENTELEMETRY_EXPORTER=grpc
        - TYK_GW_OPENTELEMETRY_ENDPOINT=otel-collector:4317
    volumes:
      - ./deployments/tyk-gateway/apps:/opt/tyk-gateway/apps
      - ./deployments/tyk-gateway/tyk.conf:/opt/tyk-gateway/tyk.conf
    depends_on:
      - tyk-redis
  tyk-redis:
    image: redis:6.0.4
    ports:
      - "6379:6379"
    volumes:
      - tyk-redis-data:/data
    networks:
      - tyk

  # Demo services
  go-httpbin:
    image: mccutchen/go-httpbin:latest
    ports:
      - "8081:8080"
    networks:
      - tyk

  reservation:
    image: nodejs-reservation
    build: ./deployments/reservation 
    ports:
      - "8091:8091"

  # Observability stack

  # Jaeger
  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    networks:
      - tyk
    ports:
      - "16686:16686"
      - "4317:4317"

  # Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    volumes:
      - ./deployments/otel-collector/otel-collector.yml:/etc/otel-collector.yml
    command: [ "--config=/etc/otel-collector.yml" ]
    networks:
      - tyk
    ports:
      - "1888:1888"   # pprof extension
      - "13133:13133" # health_check extension
      - "55670:55679" # zpages extension
      - "4317"          # OTLP over gRPC receiver
      - "4318:4318"     # OTLP over HTTP receiver
      - "9464"          # Prometheus exporter
      - "8888"          # metrics endpoint
    depends_on:
      - jaeger-all-in-one

  # Prometheus
  prometheus:
    image: prom/prometheus
    volumes:
      - ./deployments/prometheus/:/prometheus
      - ./data/prometheus:/data
    command:
      - '--config.file=/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/data'
    ports:
      - "9090:9090"
    networks:
      - tyk

  # K6 for load testing
  k6:
    image: grafana/k6:latest
    networks:
      - tyk
    ports:
      - "6565:6565"
    volumes:
      - ./deployments/k6/:/scripts

  # Grafana 
  grafana:
    image: grafana/grafana-oss
    ports:
      - 3000:3000
    volumes:
      - ./deployments/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources/
      - ./deployments/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards/
      - ./data/grafana/:/var/lib/grafana
      - ./deployments/grafana/provisioning/img/tyk-opentelemetry.png:/usr/share/grafana/public/img/tyk-opentelemetry.png
    networks:
      - tyk

  opensearch-node1: # This is also the hostname of the container within the Docker network (i.e. https://opensearch-node1/)
    image: opensearchproject/opensearch:latest # Specifying the latest available image - modify if you want a specific version
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node1 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes eligible to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=TykOpenSearch1234!   # Sets the demo admin user password when using demo configuration, required for OpenSearch 2.12 and later
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data1:/usr/share/opensearch/data # Creates volume called opensearch-data1 and mounts it to the container
    ports:
      - 9200:9200 # REST API
      - 9600:9600 # Performance Analyzer
    networks:
      - tyk # All of the containers will join the same Docker bridge network
  opensearch-node2:
    image: opensearchproject/opensearch:latest # This should be the same image used for opensearch-node1 to avoid issues
    container_name: opensearch-node2
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node2
      - discovery.seed_hosts=opensearch-node1,opensearch-node2
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=TykOpenSearch1234!
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch-data2:/usr/share/opensearch/data
    networks:
      - tyk
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:latest # Make sure the version of opensearch-dashboards matches the version of opensearch installed on other nodes
    container_name: opensearch-dashboards
    ports:
      - 5601:5601 # Map host port 5601 to container port 5601
    expose:
      - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
    environment:
      OPENSEARCH_HOSTS: '["https://opensearch-node1:9200","https://opensearch-node2:9200"]' # Define the OpenSearch nodes that OpenSearch Dashboards will query
    networks:
      - tyk
  data-prepper:
    container_name: data-prepper
    image: opensearchproject/data-prepper:latest
    volumes:
      - ./deployments/opensearch/pipelines.yaml:/usr/share/data-prepper/pipelines/pipelines.yaml
    ports:
      - 21890:21890
    networks:
      - tyk  

volumes:
  tyk-redis-data:
  grafana-data:
  opensearch-data1:
  opensearch-data2:

networks:
  tyk:
